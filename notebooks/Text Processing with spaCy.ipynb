{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing with spaCy\n",
    "Exploring basic processes using the spaCy python package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from spacy.en import English\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Document\n",
    "The nlp command instantiates the in memory document into the spacy english model class so we can perform operations on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/11-0.txt','r') as f:\n",
    "    alice_text = f.read()\n",
    "    \n",
    "doc = nlp(alice_text)  # Instantiate the document as a spacy.english model class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokens are building blocks that form a setence, breaking them down is called tokenization. The object that is created from the instantiation represents the words as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last\n"
     ]
    }
   ],
   "source": [
    "# Get the 100th token of the document.\n",
    "token = doc[99]\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences\n",
    "In some circumstances it's better to process a document by individual sentences. SpaCy exposes this as the ```sents``` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences found: 1431\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She took down a jar from one of the shelves as she passed; it was labelled ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORANGE MARMALADE’, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.  ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well!’ thought Alice to herself, ‘after such a fall as this, I shall think nothing of tumbling down stairs!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How brave they’ll all think me at home!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why, I wouldn’t say anything about it, even if I fell off the top of the house!’ (Which was very likely true.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Down, down, down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Would the fall NEVER come to an end! ‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I wonder how many miles I’ve fallen by this time?’ she said aloud. ‘</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                               0\n",
       "0  Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next.                                                                                                           \n",
       "1  First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.\n",
       "2  She took down a jar from one of the shelves as she passed; it was labelled ‘                                                                                                                                                                                                 \n",
       "3  ORANGE MARMALADE’, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.  ‘                                                                       \n",
       "4  Well!’ thought Alice to herself, ‘after such a fall as this, I shall think nothing of tumbling down stairs!                                                                                                                                                                  \n",
       "5  How brave they’ll all think me at home!                                                                                                                                                                                                                                      \n",
       "6  Why, I wouldn’t say anything about it, even if I fell off the top of the house!’ (Which was very likely true.)                                                                                                                                                               \n",
       "7  Down, down, down.                                                                                                                                                                                                                                                            \n",
       "8  Would the fall NEVER come to an end! ‘                                                                                                                                                                                                                                       \n",
       "9  I wonder how many miles I’ve fallen by this time?’ she said aloud. ‘                                                                                                                                                                                                         "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sentence.orth_.replace('\\n', ' ') for sentence in doc.sents]  # List comp, also replacing newline chars\n",
    "print('Sentences found: ' + str(len(sentences)))\n",
    "pd.DataFrame(sentences[10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Chunks \n",
    "These are phrases build from recovered nouns from speech tags, we can access this using the ```noun_chunks``` attribute which returns a generator of the clusters of nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, anything, it, I, the top, the house!’]\n"
     ]
    }
   ],
   "source": [
    "# Example sentence from alice (6)\n",
    "subset_sentence = nlp(\"Why, I wouldn’t say anything about it, even if I fell off the top of the house!’ (Which was very likely true.)\")\n",
    "print([chunk for chunk in subset_sentence.noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Noun Phrases\n",
    "Noun phrases can be helpful for determining the topic of text. This operation can also be perfomed on the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total noun phrases: 8025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she</td>\n",
       "      <td>peeped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the\\nbook</td>\n",
       "      <td>reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her sister</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no pictures</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conversations</td>\n",
       "      <td>pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the use</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a book,’</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1\n",
       "0  she            peeped  \n",
       "1  the\\nbook      reading \n",
       "2  her sister     was     \n",
       "3  it             had     \n",
       "4  no pictures    had     \n",
       "5  conversations  pictures\n",
       "6  it             in      \n",
       "7  what           is      \n",
       "8  the use        thought \n",
       "9  a book,’       thought "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrases = [[np.orth_, np.root.head.orth_] for np in doc.noun_chunks]\n",
    "print('Total noun phrases: ' + str(len(noun_phrases)))\n",
    "pd.DataFrame(noun_phrases[30:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords using noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-PRON-', 2700),\n",
       " ('alice', 331),\n",
       " ('the queen', 55),\n",
       " ('the king', 52),\n",
       " ('the gryphon', 50),\n",
       " ('the hatter', 48),\n",
       " ('the mock turtle', 45),\n",
       " ('-PRON- head', 36),\n",
       " ('the duchess', 34),\n",
       " ('the dormouse', 27)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = Counter()\n",
    "for chunk in doc.noun_chunks:\n",
    "    if nlp.vocab[chunk.lemma_].prob < - 8:  # Probability value of neg 8 is the threshold\n",
    "           keywords[chunk.lemma_] += 1\n",
    "keywords.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities\n",
    "In information extraction it's useful to use a named entity recognition tool to be able to identify persons, organizations, locations, time, quanity, values and other categorical distinctions of tokens. This is exposed as the ```ents``` attribute and the example will show a subset of the top 5 person entities within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice      368\n",
       "Gryphon    42 \n",
       "Queen      32 \n",
       "Mock       25 \n",
       "Mouse      22 \n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = list(doc.ents)  # Create list of documents entities\n",
    "people = [entity.orth_ for entity in entities if entity.label_ in ['PERSON']]\n",
    "pd.DataFrame(people)[0].value_counts()[:5]  # Print out the top five person entities within the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech\n",
    "POS tagging is a method to assign the grammar tags given a word within a current context. This is very helpful when building nlp systems. These tags can be found from each individual token using the ```x.pos_``` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last - ADJ\n",
      "Updated - VERB\n",
      ": - PUNCT\n",
      "October - PROPN\n",
      "6 - NUM\n",
      ", - PUNCT\n",
      "2016 - NUM\n",
      "\n",
      "\n",
      " - SPACE\n",
      "Language - NOUN\n",
      ": - PUNCT\n",
      "English - PROPN\n"
     ]
    }
   ],
   "source": [
    "for token in doc[99:110]:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word to Vector\n",
    "Word vectors are a way to represent distributional similarity of words within a text. A popular method for training is using word2vect. SpaCy uses GloVe as an unsupervised algorithm to get the vector representation of words from the text supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar words to cat: \n",
      "cats\n",
      "kitten\n",
      "dog\n",
      "kitty\n",
      "pet\n",
      "puppy\n",
      "dogs\n",
      "rabbit\n",
      "pets\n",
      "animal\n"
     ]
    }
   ],
   "source": [
    "parser = English()\n",
    "\n",
    "# Find word vector for cat\n",
    "cat = parser.vocab['cat']\n",
    "\n",
    "# Cosine similarity function\n",
    "cosine = lambda v1, v2: dot(v1, v2) / (norm(v1)*norm(v2))\n",
    "others = list({w for w in doc.vocab if w.has_vector and w.orth_.islower() and w.lower_ != \"cat\"})\n",
    "\n",
    "# Sort by similarity scores\n",
    "others.sort(key=lambda w:cosine(w.vector, cat.vector))\n",
    "others.reverse()\n",
    "\n",
    "print('Top similar words to cat: ')\n",
    "for i in others[:10]:\n",
    "    print(i.orth_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity\n",
    "SpaCy has a built-in similarity method that can help us identify word similarity using a semantic similarity estimate using cosine similarity through an average of word vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734707011482\n"
     ]
    }
   ],
   "source": [
    "cats = others[0]\n",
    "kitten = others[1]\n",
    "print(cats.similarity(kitten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Resources\n",
    "\n",
    "* http://gutenberg.org\n",
    "\n",
    "* https://spacy.io\n",
    "\n",
    "* https://blog.sharepointexperience.com/2016/01/nlp-and-sharepoint-part-1/\n",
    "\n",
    "* https://www.analyticsvidhya.com/blog/2017/04/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python/\n",
    "\n",
    "* https://github.com/cytora/pycon-nlp-in-10-lines/\n",
    "\n",
    "* https://spacy.io/docs/api/doc\n",
    "\n",
    "Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll\n",
    "\n",
    "This eBook is for the use of anyone anywhere at no cost and with\n",
    "almost no restrictions whatsoever.  You may copy it, give it away or\n",
    "re-use it under the terms of the Project Gutenberg License included\n",
    "with this eBook or online at www.gutenberg.org\n",
    "\n",
    "\n",
    "Title: Alice’s Adventures in Wonderland\n",
    "\n",
    "Author: Lewis Carroll\n",
    "\n",
    "Posting Date: June 25, 2008 [EBook #11]\n",
    "Release Date: March, 1994\n",
    "Last Updated: October 6, 2016\n",
    "\n",
    "Language: English\n",
    "\n",
    "Character set encoding: UTF-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
